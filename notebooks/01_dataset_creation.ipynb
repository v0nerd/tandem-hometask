{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "\n",
    "This notebook demonstrates the creation of a synthetic dataset for the Domain Name Suggestion LLM project. The dataset includes business descriptions and corresponding domain name suggestions across various industries, business types, tones, and complexity levels.\n",
    "\n",
    "## Objectives\n",
    "- Generate 1,000 diverse training examples (configurable).\n",
    "- Ensure diversity across industries, business types, and tones.\n",
    "- Validate dataset quality and generate summary statistics.\n",
    "- Save the dataset in JSON format for training and evaluation.\n",
    "\n",
    "## Setup\n",
    "Ensure the project environment is set up by running `bash scripts/setup_environment.sh` and installing dependencies from `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from data.dataset_creation import SyntheticDatasetCreator\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define the parameters for dataset creation, including the number of samples and output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NUM_SAMPLES = 1000\n",
    "OUTPUT_PATH = 'data/synthetic/training_data.json'\n",
    "CONFIG_PATH = 'config/model_config.yaml'\n",
    "\n",
    "# Initialize dataset creator\n",
    "creator = SyntheticDatasetCreator(CONFIG_PATH)\n",
    "logger.info(f'Initialized dataset creator with config: {CONFIG_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Business Descriptions\n",
    "\n",
    "Let's generate a few sample business descriptions to verify the diversity and quality of the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5 sample business descriptions\n",
    "for i in range(5):\n",
    "    desc = creator.generate_business_description()\n",
    "    print(f'\\nSample {i+1}:')\n",
    "    print(f'Description: {desc.description}')\n",
    "    print(f'Industry: {desc.industry}')\n",
    "    print(f'Business Type: {desc.business_type}')\n",
    "    print(f'Tone: {desc.tone}')\n",
    "    print(f'Keywords: {desc.keywords[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Full Dataset\n",
    "\n",
    "Generate the complete dataset with the specified number of samples and save it to the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "logger.info(f'Generating dataset with {NUM_SAMPLES} samples...')\n",
    "creator.create_training_dataset(num_samples=NUM_SAMPLES, output_path=OUTPUT_PATH)\n",
    "logger.info(f'Dataset saved to {OUTPUT_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Validation\n",
    "\n",
    "Validate the generated dataset to ensure quality and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset(dataset_path):\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    logger.info(f'Validating dataset with {len(dataset)} examples')\n",
    "    \n",
    "    # Basic validation checks\n",
    "    assert isinstance(dataset, list), 'Dataset must be a list'\n",
    "    assert len(dataset) > 0, 'Dataset is empty'\n",
    "    \n",
    "    for i, example in enumerate(dataset):\n",
    "        assert 'input' in example, f'Example {i} missing input'\n",
    "        assert 'output' in example, f'Example {i} missing output'\n",
    "        assert 'metadata' in example, f'Example {i} missing metadata'\n",
    "        assert '.' in example['output'], f'Example {i} output is not a valid domain'\n",
    "    \n",
    "    logger.info('Dataset validation passed')\n",
    "\n",
    "validate_dataset(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "\n",
    "Analyze the generated dataset to understand its distribution and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "with open(OUTPUT_PATH, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "metadata_df = pd.json_normalize(df['metadata'])\n",
    "\n",
    "# Plot industry distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=metadata_df, x='industry', order=metadata_df['industry'].value_counts().index)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Industry Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot TLD distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=metadata_df, x='tld')\n",
    "plt.title('TLD Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print('Dataset Summary:')\n",
    "print(f'Total Examples: {len(dataset)}')\n",
    "print(f'Unique Inputs: {df[\"input\"].nunique()}')\n",
    "print(f'Unique Outputs: {df[\"output\"].nunique()}')\n",
    "print(f'Average Input Length: {df[\"input\"].str.len().mean():.1f} chars')\n",
    "print(f'Average Output Length: {df[\"output\"].str.len().mean():.1f} chars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The dataset creation process successfully generated a diverse set of business descriptions and domain name suggestions. The dataset is validated and ready for use in model training. The next step is to train the baseline model using this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
